---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  collapse = TRUE,
  echo = TRUE,
  comment = "#>"
)

library(RefManageR)
```

```{r bib, include = FALSE, echo = FALSE}
bib <- RefManageR::ReadBib("files/ref.bib")
RefManageR::NoCite(bib)
```

# Multiverse meta-analysis

This project aim to implement a framework for valid statistical inference for a multiverse analysis. The method is based on a multivariate permutation testing framework.

This is a work in progress project with the aim to develop the `joinmeta` package to perform a multiverse meta-analysis. Now the project depends on:

```{r packages, eval = FALSE}
pckgs <- c("metafor", "flip")
install.packages(pckgs)
```

Furthermore there is the temporary need to install the [`jointest`](https://github.com/livioivil/jointest) package available on Github:

```{r jointest, eval = FALSE}
devtools::install_github("livioivil/jointest")
```

# Minimal example

To perform a multiverse meta-analysis you can clone this repository and open the R Project. Then we can load the relevant packages:

```{r}
devtools::load_all() # to load all functions in the projects
library(metafor)
library(Matrix)
library(MASS)
library(jointest)
library(flip)
```

Then we can simulate a multiverse matrix. In real applications the matrix is the result of fitting different models on the same dataset creating several different scenarios.

```{r}
# seed for the simulation
set.seed(2080)

# Multiverse
ns <-  162 # number of multiverse scenarios
nc <- ns^2/2 - ns/2 # number of correlations

# Meta-analysis
k <- 30 # number of studies
theta <- 0.4 # real effect size
tau2 <- 0.2 # real heterogeneity
n <- 30 # sample size for each group per study

# Effect sizes
yi <- rnorm(k, rnorm(k, theta, sqrt(tau2)), sqrt(1/n + 1/n))

# Sampling variances
vi <- (rchisq(k, n + n - 2) / (n + n - 2)) * (1/n + 1/n)

# this is a single hypothetical meta-analysis
fit <- rma(yi, vi, method = "REML")

# Now we simulate some variability in effect sizes and sampling variances
# due to different analytically approach to the meta-analysis. For example
# guessing a missing correlation, removing a study or choosing a specific
# meta-analysis model

b <- fit$b # average effect
se <- fit$se # standard error

bs <- runif(ns, b - b*0.5, b + b*0.5) # some variability in the average effect
rs <- runif(nc, 0.6, 1) # correlations between scenarios
ses <- runif(ns, se - 0.25*se, se + 0.25*se) # some variability in the standard error

# correlation matrix of the multiverse
R <- matrix(NA, ns, ns)
R[upper.tri(R)] <- rs
R[lower.tri(R)] <- rs
diag(R) <- 1

# variance-covariance matrix of the multiverse
V <- diag(sqrt(ses^2 + tau2)) %*% R %*% diag(sqrt(ses^2 + tau2))
V <- as.matrix(Matrix::nearPD(V)$mat) # make positive definite

# generating observed effects across the multiverse
X <- MASS::mvrnorm(k, bs, V)

# fitting a meta-analysis model for each scenario

fitl <- vector(mode = "list", length = ns)

for(i in 1:ns){
  # some variability in the sampling variances
  vis <- runif(k, vi - 0.25*vi, vi + 0.25*vi)
  fitl[[i]] <- rma(X[, i], vis)
}

# fitl is the list of fitted models to each multiverse scenario. this is usually the starting point for the multiverse analysis.
```

Now we can combine the multiverse obtaining the overall p-value and the post-hoc corrected p-values for each scenario.

```{r}
# permutations of each scenario
multi <- multiverse(fitl)

multi_comb <- jointest::combine(multi)

# overall pvalue
summary(multi_comb)

# adjusting each p-value using maxT
res <- p_adjust_fwer(multi, method = "maxT")
head(summary(res))
```

# Conferences

- Poster at [SIPS 2023](https://www.improvingpsych.org/SIPS2023/): [HTML](conferences/sips2023/poster/sips-2023.html), [PDF](conferences/sips2023/poster/sips-2023.pdf)

# Suggested References

```{r, results='asis', echo = FALSE}
RefManageR::PrintBibliography(bib)
```
